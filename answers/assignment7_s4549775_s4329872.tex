\documentclass[12pt, a4paper]{article}

\usepackage{amssymb}
\usepackage{multicol}
\usepackage{enumerate}
\usepackage[top=5em, bottom=5em, left=5em, right=5em]{geometry}
\usepackage{listings}
\usepackage{tikz}
\usetikzlibrary{positioning}

\setlength\parskip{1em}
\setlength\parindent{0em}

\title{Assignment 7}

\author{Hendrik Werner s4549775}

\begin{document}
\maketitle

This was done in collaboration with Constantin Blach (s4329872).

\section{} %1
After inserting all values the binary search tree looks as follows:

\begin{tikzpicture}[c/.style={circle, draw, minimum width=2em}]
	\node[c] (A) {9};
	\node[c, below left=8em of A] (B) {5};
	\node[c, below right=8em of A] (C) {12};
	\node[c, below left=of B] (D) {4};
	\node[c, below right=of B] (E) {7};
	\node[c, below left=of C] (F) {10};
	\node[c, below right=of C] (G) {18};
	\node[c, below right=of F] (H) {11};
	\node[c, below right=of E] (I) {8};

	\draw (A) -- (B);
	\draw (A) -- (C);
	\draw (B) -- (D);
	\draw (B) -- (E);
	\draw (C) -- (F);
	\draw (C) -- (G);
	\draw (E) -- (I);
	\draw (F) -- (H);
\end{tikzpicture}

After removing $9$ is looks like this:

\begin{tikzpicture}[c/.style={circle, draw, minimum width=2em}]
	\node[c] (A) {10};
	\node[c, below left=8em of A] (B) {5};
	\node[c, below right=8em of A] (C) {12};
	\node[c, below left=of B] (D) {4};
	\node[c, below right=of B] (E) {7};
	\node[c, below left=of C] (F) {11};
	\node[c, below right=of C] (G) {18};
	\node[c, below right=of E] (I) {8};

	\draw (A) -- (B);
	\draw (A) -- (C);
	\draw (B) -- (D);
	\draw (B) -- (E);
	\draw (C) -- (F);
	\draw (C) -- (G);
	\draw (E) -- (I);
\end{tikzpicture}

After removing $5$ is looks like this:

\begin{tikzpicture}[c/.style={circle, draw, minimum width=2em}]
	\node[c] (A) {10};
	\node[c, below left=8em of A] (B) {7};
	\node[c, below right=8em of A] (C) {12};
	\node[c, below left=of B] (D) {4};
	\node[c, below right=of B] (E) {8};
	\node[c, below left=of C] (F) {11};
	\node[c, below right=of C] (G) {18};

	\draw (A) -- (B);
	\draw (A) -- (C);
	\draw (B) -- (D);
	\draw (B) -- (E);
	\draw (C) -- (F);
	\draw (C) -- (G);
\end{tikzpicture}

\section{} %2
\begin{enumerate}
	\item Every node has $3$ pointers which are all initially $NIL$.
	\label{sec2:ppn}

	\item (\ref{sec2:ppn}) means that in the trivial case of a $1$-node BST there are $3$ $NIL$-pointers.
	\label{sec2:trivial}

	\item Pointers are connected pairwise.

	$(\forall left_i, \exists p_j, left_i \neq NIL \leftrightarrow p_j \neq NIL) \land (\forall right_i, \exists p_j, right_i \neq NIL \leftrightarrow p_j \neq NIL)$
	\label{sec2:pcp}

	\item (\ref{sec2:ppn}, \ref{sec2:trivial}, and \ref{sec2:pcp}) can be expressed as a recurrence relation:

	$N_1 = 3$\\
	$N_k = N_{k - 1} + 1$

	where $N_k$ is the number of $NIL$-pointers in a $k$-node BST.

	\begin{itemize}
		\item associated homogeneous recurrence relation: $N_k = N_{k - 1}$
		\item characteristic equation: $r - 1 = 0$
		\item $r_1 = 1, m_1 = 1$
	\end{itemize}
	\label{sec2:rr}

	\item (\ref{sec2:rr}) can be expressed as $f(n) = n + 2$.
\end{enumerate}

\section{} %3
In the worst case scenario the new key must be appended at height $h+1$ in a tree of height $h$. We do $O(1)$ work at non-leaf node, deciding whether to go left or right. We do this a maximum of $O(h - 1)$ times because we increase $h$ on every step and the nodes at height $h$ must be leaf nodes.

At the leaf node we do $O(1)$ work of pointing this leaf to our new key and the new key to the leaf.

The total, worst case time complexity of inserting a key is $O(h - 1 + 1) = O(h)$.

\section{} %4
It is easier to balance trees using the CLRS definition. Suppose we insert the key $k$ 7 times: We could store this in a tree of depth $3$ the using the CLRS definition whereas the resulting tree using the Data Structures \& Algorithms in C++ (DSAC) definition would need to be of depth $7$.

A more balanced tree is desirable because many tree operation's time and space complexity depend on the height of the tree.

The search operation is much easier to implement using the DSAC definition because we always know to go right whereas using the CLRS definition we need to consider both children when searching for $k$ in the scenario proposed above.

\section{} %5
You begin at the root node $p = T.root$. Probe node $p$ and both of its children $l, r$. If $p < l \land p < r$ then return $p$ else if $l < r$ then $p = l, l = p.left, r = p.right$ else $p = r, l = p.left, r = p.right$. Repeat the last step. (Note: $probe(NIL) = \infty$, important for leaf nodes)

Probe complexity: We probe $3$ nodes at every step ($O(1)$) and do this a maximum of $O(\log n)$ times because it's a complete tree and we split the remaining work in half at each step. We do a total of $O(\log n)$ probes.

Correctness:
We would not be at node $p$ if $p.parent < p$ and we know $p \neq p.parent \neq l \neq r$. If node $p$ is the smallest of the $3$ nodes we probe then we know it is a local minimum. If either of $r, l$ is smaller then $p$ is no local minimum, and we proceed with the test on it's smaller child node because the bigger child already cannot be a local minimum.

Because we increase depth on every step the algorithm is guaranteed to terminate and also find a local minimum as all leaf nodes reached with this method are smaller than their parent and aren't connected to other nodes which means when we reach a leaf node it's guaranteed to be a local minimum. (It's also possible to find one earlier.)

\end{document}
